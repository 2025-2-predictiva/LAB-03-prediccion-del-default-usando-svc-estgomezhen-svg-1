{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b7e287",
   "metadata": {},
   "source": [
    "# Predicción de Default de Clientes con Regresión Logística\n",
    "\n",
    "En este cuaderno desarrolla un modelo de clasificación para predecir si un cliente\n",
    "incurrirá en default el próximo mes. El dataset incluye 23 variables relacionadas\n",
    "con historial crediticio, pagos y características demográficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df56240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score, balanced_accuracy_score, recall_score,\n",
    "    f1_score, confusion_matrix\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeeb8fd",
   "metadata": {},
   "source": [
    "# Paso 1.\n",
    "Realice la limpieza de los datasets:\n",
    "Renombre la columna \"default payment next month\" a \"default\".\n",
    "Remueva la columna \"ID\".\n",
    "Elimine los registros con informacion no disponible.\n",
    "Para la columna EDUCATION, valores > 4 indican niveles superiores\n",
    "de educación, agrupe estos valores en la categoría \"others\".\n",
    "Renombre la columna \"default payment next month\" a \"default\"\n",
    "Remueva la columna \"ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eef9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "#carga de datos\n",
    "train = pd.read_csv(\n",
    "    \"../files/input/train_data.csv.zip\",\n",
    "    compression=\"zip\",\n",
    ")\n",
    "test = pd.read_csv(\n",
    "    \"../files/input/test_data.csv.zip\",\n",
    "    compression=\"zip\",\n",
    ")\n",
    "print(\"Datos cargados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f19d50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preprocesados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Renombrar variable objetivo\n",
    "train = train.rename(columns={\"default payment next month\": \"default\"})\n",
    "test = test.rename(columns={\"default payment next month\": \"default\"})\n",
    "\n",
    "# Eliminar columna ID \n",
    "if \"ID\" in train.columns:\n",
    "    train = train.drop(columns=[\"ID\"])\n",
    "if \"ID\" in test.columns:\n",
    "    test = test.drop(columns=[\"ID\"])\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "\n",
    "# EDUCATION > 4 se agrupa en categoría \"otros\" (4)\n",
    "train[\"EDUCATION\"] = train[\"EDUCATION\"].clip(upper=4)\n",
    "test[\"EDUCATION\"] = test[\"EDUCATION\"].clip(upper=4)\n",
    "\n",
    "print(\"Datos preprocesados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abb6c7",
   "metadata": {},
   "source": [
    "# Paso 2.\n",
    " Divida los datasets en x_train, y_train, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d766a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables independientes y dependientes separadas.\n"
     ]
    }
   ],
   "source": [
    "x_train = train.drop(columns=[\"default\"])\n",
    "y_train = train[\"default\"]\n",
    "\n",
    "x_test = test.drop(columns=[\"default\"])\n",
    "y_test = test[\"default\"]\n",
    "\n",
    "print(\"Variables independientes y dependientes separadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5927a",
   "metadata": {},
   "source": [
    "# Paso 3.\n",
    "Cree un pipeline para el modelo de clasificación. Este pipeline debe contener las siguientes capas:\n",
    "\n",
    " - Transforma las variables categoricas usando el método one-hot-encoding.\n",
    " - Descompone la matriz de entrada usando PCA. El PCA usa todas las componentes.\n",
    " - Estandariza la matriz de entrada.\n",
    " - Selecciona las K columnas mas relevantes de la matrix de entrada.\n",
    " - Ajusta una maquina de vectores de soporte (svm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108fdf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesador creado.\n"
     ]
    }
   ],
   "source": [
    "# Variables categóricas y numéricas\n",
    "categorical = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "numeric = [col for col in x_train.columns if col not in categorical]\n",
    "\n",
    "# OneHotEncoder solo sobre categóricas, resto pasa tal cual\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            categorical,\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "print(\"Preprocesador creado.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190f852",
   "metadata": {},
   "source": [
    "# Paso 4.\n",
    "- Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "- Use 10 splits para la validación cruzada. Use la función de precision\n",
    "- balanceada para medir la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7962f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline creado.\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),               # contiene OneHotEncoder\n",
    "        (\"scaler\", StandardScaler()),                 # aparece StandardScaler\n",
    "        (\"pca\", PCA()),                               # PCA con todas las componentes\n",
    "        (\"selector\", SelectKBest(score_func=f_classif)),\n",
    "        (\"svm\", SVC()),\n",
    "    ]\n",
    ")\n",
    "print(\"Pipeline creado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d2434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Mejores parámetros: {'selector__k': 20, 'svm__C': 10, 'svm__gamma': 'auto', 'svm__kernel': 'rbf'}\n",
      "Mejor balanced_accuracy (cv): 0.6455126994487348\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"selector__k\": [20, 25],\n",
    "    \"svm__C\": [1, 10, 20],\n",
    "    \"svm__kernel\": [\"rbf\"],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=10,        # el enunciado pide 10 folds\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor balanced_accuracy (cv):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d7d0e",
   "metadata": {},
   "source": [
    "# Paso 5.\n",
    "- Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "- Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4728e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en 'files/models/model.pkl.gz'.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../files/models\", exist_ok=True)\n",
    "\n",
    "with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump(grid, f)\n",
    "print(\"Modelo guardado en 'files/models/model.pkl.gz'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56f692",
   "metadata": {},
   "source": [
    "# Paso 6.\n",
    "- Calcule las metricas de precision, precision balanceada, recall, y f1-score para los conjuntos de entrenamiento y prueba.\n",
    "- Guardelas en el archivo files/output/metrics.json. Cada fila del archivo es un diccionario con las metricas de un modelo.\n",
    "- Este diccionario tiene un campo para indicar si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "- - {'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "- - {'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db8f8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo en conjunto de entrenamiento...\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(model, X, y, name):\n",
    "    y_pred = model.predict(X)\n",
    "    return {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": name,\n",
    "        \"precision\": float(precision_score(y, y_pred)),\n",
    "        \"balanced_accuracy\": float(balanced_accuracy_score(y, y_pred)),\n",
    "        \"recall\": float(recall_score(y, y_pred)),\n",
    "        \"f1_score\": float(f1_score(y, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def cm_to_dict(cm, name):\n",
    "    return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": name,\n",
    "        \"true_0\": {\n",
    "            \"predicted_0\": int(cm[0, 0]),\n",
    "            \"predicted_1\": int(cm[0, 1]),\n",
    "        },\n",
    "        \"true_1\": {\n",
    "            \"predicted_0\": int(cm[1, 0]),\n",
    "            \"predicted_1\": int(cm[1, 1]),\n",
    "        },\n",
    "    }\n",
    "print(\"Evaluando modelo en conjunto de entrenamiento...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4834870",
   "metadata": {},
   "source": [
    "# Paso 7.\n",
    "- Calcule las matrices de confusion para los conjuntos de entrenamiento y prueba. \n",
    "- Guardelas en el archivo files/output/metrics.json. Cada fila del archivo es un diccionario con las metricas de un modelo. de entrenamiento o prueba. Por ejemplo:\n",
    "- - {'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    "- -{'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff75c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación completada.\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# Métricas\n",
    "metrics.append(compute_metrics(grid, x_train, y_train, \"train\"))\n",
    "metrics.append(compute_metrics(grid, x_test, y_test, \"test\"))\n",
    "\n",
    "# Matrices de confusión\n",
    "cm_train = confusion_matrix(y_train, grid.predict(x_train))\n",
    "cm_test = confusion_matrix(y_test, grid.predict(x_test))\n",
    "\n",
    "metrics.append(cm_to_dict(cm_train, \"train\"))\n",
    "metrics.append(cm_to_dict(cm_test, \"test\"))\n",
    "print(\"Evaluación completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c322b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '../files/output/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m output_path = \u001b[33m\"\u001b[39m\u001b[33m../files/output/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[32m      5\u001b[39m         f.write(json.dumps(entry) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Analitica\\Predictiva\\Laboratorios\\LAB-03-prediccion-del-default-usando-svc-estgomezhen-svg-1\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: '../files/output/'"
     ]
    }
   ],
   "source": [
    "output_path = \"../files/output/\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in metrics:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"Guardado en:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
